$(document).ready(function () {indexDict['en'] = [{ "title" : "Unravel 4.3", 
"url" : "unravel-4-3.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3", 
"snippet" : "...", 
"body" : " " }, 
{ "title" : "This Documentation is for Unravel Version 4.3", 
"url" : "unravel-4-3.html#UUID-cf26a2d6-427f-5e20-e5d4-d09fdc2c4890_id_Unravel43-ThisDocumentationisforUnravelVersion43", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ This Documentation is for Unravel Version 4.3", 
"snippet" : "Documentation for Prior Versions Unravel 4.2 For older documentation, contact Unravel Support Downloads Compatibility Matrix Unravel Software Versions New Users Overview Frequently Asked Questions (FAQ) Release Notes v4.3 | v4.3.1.0 v4.3.1.1 v4.3.1.2 v4.3.1.3 | v4.3.1.4 | v4.3.1.5 v4.3.1.6 v4.3.1.7 ...", 
"body" : " \n \n \n Documentation for\nPrior Versions \n Unravel 4.2 For older documentation, contact Unravel Support Downloads \n Compatibility\nMatrix \n Unravel Software\nVersions \n New Users \n Overview \n Frequently Asked Questions\n(FAQ) Release Notes \n v4.3 | v4.3.1.0 v4.3.1.1 v4.3.1.2 v4.3.1.3 | v4.3.1.4 | v4.3.1.5 v4.3.1.6 v4.3.1.7 v4.3.1.9 v4.3.1.10 *not available \n access \n adding \n advanced \n amazon-emr \n apm \n appendix \n applications \n auto-actions \n azure \n cdh \n cloudera \n cluster \n cm \n configure \n custom-config \n detecting \n emr \n hadoop \n hdp \n hive \n hortonworks \n installation \n kafka \n kerberos \n mapr \n metastore \n properties \n quoble \n release-notes \n security \n security-config \n spark \n tez \n ui \n unravel-4-3 \n unravel-sensor \n unravel-server \n use-case \n user-guide \n workflows " }, 
{ "title" : "Overview", 
"url" : "unravel-4-3/overview.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Overview", 
"snippet" : "...", 
"body" : "" }, 
{ "title" : "Where Does Unravel Server Reside?", 
"url" : "unravel-4-3/overview.html#UUID-736e9383-473a-f9b3-aa12-2fbf7e7a1fd9_id_Overview-WhereDoesUnravelServerReside", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Overview \/ Where Does Unravel Server Reside?", 
"snippet" : "Unravel Server is positioned in a Hadoop cluster on its own Gateway\/Edge node to communicate with HDFS and TaskTracker nodes, and to enable client access to Unravel Web UI. A basic deployment takes two hours or less. The Unravel Server on a Gateway\/Edge Node in a Hadoop Cluster...", 
"body" : "Unravel Server is positioned in a Hadoop cluster on its own\nGateway\/Edge node to communicate with HDFS and TaskTracker nodes,\nand to enable client access to Unravel Web UI. A basic deployment\ntakes two hours or less. \n The Unravel Server on a Gateway\/Edge Node in a Hadoop\nCluster " }, 
{ "title" : "What Does a Basic Deployment Provide?", 
"url" : "unravel-4-3/overview.html#UUID-736e9383-473a-f9b3-aa12-2fbf7e7a1fd9_id_Overview-WhatDoesaBasicDeploymentProvide", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Overview \/ What Does a Basic Deployment Provide?", 
"snippet" : "Once deployed, Unravel Server begins to collect information from relevant services like YARN, Hive, Oozie, Spark, Pig, and MapReduce jobs via HDFS, analyze this information, and store its analyses in its database. Unravel Web UI displays information from the database, as well as real-time event stre...", 
"body" : "Once deployed, Unravel Server begins to collect information\nfrom relevant services like YARN, Hive, Oozie, Spark,\nPig, and MapReduce jobs via HDFS, analyze this information, and\nstore its analyses in its database. Unravel Web UI displays\ninformation from the database, as well as real-time event streams\nit receives directly from Unravel Server. The figure below\nillustrates the flow of information from the Hadoop cluster, to\nUnravel Server, to Unravel Web UI. \n Information Flow from the Hadoop\nCluster to Unravel Server to Unravel Web UI " }, 
{ "title" : "What Are Advanced Deployment Options?", 
"url" : "unravel-4-3/overview.html#UUID-736e9383-473a-f9b3-aa12-2fbf7e7a1fd9_id_Overview-WhatAreAdvancedDeploymentOptions", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Overview \/ What Are Advanced Deployment Options?", 
"snippet" : "After basic deployment, advanced setup steps are optional, but may include: Deploying Unravel Sensors for Hive and Spark, which can push additional metadata to Unravel Server. In YARN, enabling log aggregation. In Oozie, pushing information via the Oozie REST API....", 
"body" : "After basic deployment, advanced setup steps are optional, but\nmay include: Deploying Unravel Sensors for Hive and Spark, which can push\nadditional metadata to Unravel Server. In YARN, enabling log aggregation. In Oozie, pushing information via the Oozie REST API. " }, 
{ "title" : "Installation Guides", 
"url" : "unravel-4-3/installation-guides.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides", 
"snippet" : "Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM) Step 1: Install Unravel Server on CDH+CM Step 2: Install Unravel Sensor Parcel on CDH+CM Step 3: Enable Impala APM Hortonworks Data Platform (HDP) Step 1: Install Unravel Server on HDP Step 2: Enable Additional Data Coll...", 
"body" : " \n Cloudera Distribution Including Apache Hadoop (CDH), with\nCloudera Manager (CM) \n Step 1: Install Unravel Server on CDH+CM \n Step 2: Install Unravel Sensor Parcel on CDH+CM \n Step 3: Enable Impala APM \n Hortonworks Data Platform (HDP) \n Step 1: Install Unravel Server on HDP \n Step 2: Enable Additional Data Collection \/ Instrumentation\nfor HDP \n MapR \n Step 1: Install Unravel Server on MapR \n Step 2: Enable Additional Data Collection \/ Instrumentation\nfor MapR \n Amazon Elastic MapReduce\n(EMR) \n Step 1: Provision and\nConfigure an Unravel EC2 Instance \n Option 1: Provision an\nUnravel EC2 Instance from Our CloudFormation Template \n Option 2: Provision an\nUnravel EC2 Instance from Our Amazon Machine Image \n Option 3: Provision and\nConfigure an Unravel EC2 Instance Manually \n Step 2: Connect the Unravel\nEC2 Instance to a New\/Existing EMR Cluster \n Step 3: Set Up AWS RDS for\nUnravel DB (Optional) \n Step 4: VPC Peering for\nUnravel EC2 Node (Optional) \n Reconnecting to Your EMR\nCluster \n Deleting the Unravel EC2\nInstance \n Using Unravel to Monitor Jobs\nin Your EMR Cluster \n Azure HDinsight Clusters \n Installation Guide for Unravel\nVM \n Step 1: Install Unravel\nServer for Azure HDinsight Cluster \n Step 2: Use Script Action to\nConfigure HDinsight Cluster for Unravel \n Step 3: Updating Unravel\nInstallation \n Step 4: ARM template for\nUnravel (Optional) \n Unravel HDinsight app " }, 
{ "title" : "Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM)", 
"url" : "unravel-4-3/installation-guides/cloudera-distribution-including-apache-hadoop--cdh-,-with-cloudera-manager--cm-.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM)", 
"snippet" : "This guide is compatible with CDH 4.5 - 5.14 Hive versions 0.10.0 through 1.2.x Spark versions 1.3, 1.5, 1.6, 2.0...", 
"body" : " This guide is compatible with CDH 4.5 - 5.14 Hive versions 0.10.0 through 1.2.x Spark versions 1.3, 1.5, 1.6, 2.0 " }, 
{ "title" : "Ordered Steps", 
"url" : "unravel-4-3/installation-guides/cloudera-distribution-including-apache-hadoop--cdh-,-with-cloudera-manager--cm-.html#UUID-bd216000-5291-e74a-47d4-692e19ddeca7_id_ClouderaDistributionIncludingApacheHadoopCDHwithClouderaManagerCM-OrderedSteps", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM) \/ Ordered Steps", 
"snippet" : "Step 1: Install Unravel Server on CDH+CM Step 2: Install Unravel Sensor Parcel on CDH+CM Step 3: Enable Impala APM...", 
"body" : " \n Step 1: Install Unravel Server on CDH+CM \n Step 2: Install Unravel Sensor Parcel on CDH+CM \n Step 3: Enable Impala APM " }, 
{ "title" : "Step 1: Install Unravel Server on CDH+CM", 
"url" : "unravel-4-3/installation-guides/cloudera-distribution-including-apache-hadoop--cdh-,-with-cloudera-manager--cm-.html#UUID-b26b203d-c88e-1d51-394f-e7a3d47feb84", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM) \/ Step 1: Install Unravel Server on CDH+CM", 
"snippet" : "Table of Contents Introduction Pre-Installation Check Platform Compatibility Hardware Software Access Permissions 1. Configure the Host Machine Allocate a Cluster Gateway\/Edge\/Client Host with HDFS Access 2. Install the Unravel Server RPM on the Host Machine Get the Unravel Server RPM Make symlinks ...", 
"body" : "\n Table of Contents \n Introduction \n Pre-Installation\nCheck \n Platform\nCompatibility \n Hardware \n Software \n Access\nPermissions \n 1.\nConfigure the Host Machine \n \nAllocate a Cluster Gateway\/Edge\/Client Host with HDFS\nAccess \n \n2. Install the Unravel Server RPM on the Host Machine \n Get\nthe Unravel Server RPM \n Make\nsymlinks if required \n Install\nthe Unravel Server RPM \n \nDo Host-Specific Post-Installation Actions \n \n3. Configure Unravel Server (Basic\/Core Optional for CDH) \n Enable\nOptional Daemons \n If\nKerberos is Enabled: \n If Sentry\nis Enabled: \n Switch\nUser \n Hive\nMetastore Access \n Restart\nUnravel Server \n 4. Log\ninto Unravel Web UI \n Congratulations! \n \n5. Configure Unravel Server (Advanced Options) \n \nEnable Additional Data Collection\/Instrumentation Introduction This topic explains how to\ndeploy Unravel Server 4.4 on a CDH gateway\/edge node.\nFor instructions that correspond to older versions of Unravel\nServer, contact Unravel Support. \n Workflow Summary Pre-installation check Configure the host machine. Install the Unravel Server RPM on the host machine. Configure Unravel Server (basic\/core options). Log into Unravel Web UI. (Optional) Configure Unravel Server (advanced options). Pre-Installation Check The following installation requirements must be met for\nsuccessful installation of Unravel. Platform Compatibility CDH 5.4 - 5.14 Hadoop 1.x - 2.x Kafka 0.9, 0.10, 0.11, and 1.0 (Apache ver. equiv.) Kerberos Hive 0.9.x - 1.2.x Spark 1.3.x - 2.2.x Hardware Architecture: x86_64 Cores: 8 RAM: 64GB minimum, 128GB for medium volume (>25,000 jobs per\nday), 256GB for high volume (>50,000 jobs per day) Disk: \/usr\/local\/unravel Disk: \/srv\/unravel For 60,000+ MR jobs per day, two or more gateway\/edge nodes are\nrecommended (\"multi-host Unravel\") Software Operating System: RedHat\/Centos 6.4 - 7.4 installed libaio.x86_64 (or disabled) should be set in\n SELINUX=permissive \/etc\/selinux\/config HDFS+Hive+YARN+Spark Unravel host should be a client\/gateway\n(Hadoop and Hive commands in PATH) If Spark2 service is installed, Unravel host should be a\nclient\/gateway LDAP (AD or Open LDAP) compatible for Unravel Web UI user\nauthentication (Open signup by default) On Unravel Edge-node server, please do\nnot NTP should be running and in-sync with the cluster Access Permissions Local user unravel:unravel is created during installation, but\ncan be changed later If Kerberos is in use, a keytab for principal is required for\naccess to:\n Access to YARN’s “done dir” in HDFS Access to YARN’s log aggregation directory in HDFS Access to Spark event log directory in HDFS Access to file sizes under HIve warehouse directory Access to YARN Resource Manager REST API principal needs right to find out which RM is active JDBC access to the Hive Metastore (read-only user is\nsufficient) For Impala support, a read-only account for Cloudera Manager\nAPI is needed The RUN_AS user must be included in yarn.admin.ac, either as a\nseparate user or as a member of a group, if the cluster uses kerberos for authentication, or the resource manager has been configured in high availability\nmode. Network Port 3000 from users and entire cluster to Unravel Web UI HDFS ports open from Hadoop cluster to Unravel Server(s) For YARN, Hive Metadata DB port open to Unravel Server(s) for\npartition reporting UDP and TCP port 4043 open from entire cluster to Unravel\nServer(s) For Oozie, port 11000 open from Unravel Server(s) to the Oozie\nserver Resource Manager (RM) port 8032 from Unravel Server(s) to the\nRM server(s) Cloudera Manager (CM) port 7180 (or 7183 for HTTPS) from\nUnravel Server(s) to CM Port 4020, 4176, 4181 through 4189, 3316, 4091 must be\navailable for localhost communication between Unravel daemons or\nUnravel servers (if multi-host Unravel installation) 1. Configure the Host Machine Allocate a Cluster Gateway\/Edge\/Client Host with HDFS Access Use Cloudera Manager to create the gateway configuration for the\nUnravel server(s) that has client roles for HDFS, YARN, Spark,\nHive, and optionally Spark2. 2. Install the Unravel Server RPM on the Host Machine Get the Unravel Server RPM See Download Unravel\nSoftware Make symlinks if required If you want the two disk\nareas used by Unravel to be on different volumes, you can make\nsymlinks to specific areas before installing (or do\na mv symlink \/usr\/local\/unravel \/srv\/unravel Install the Unravel Server RPM # sudo rpm -U unravel-4.*.x86_64.rpm*\n# \/usr\/local\/unravel\/install_bin\/await_fixups.sh The precise filename can vary,\ndepending on how it was fetched or copied.\nThe rpm rpm -U Run the\nspecified await_fixups.sh await_fixups.sh DONE The installation creates \/usr\/local\/unravel\/ unravel \/srv\/unravel\/ \nThe master configuration file is\nin \/usr\/local\/unravel\/etc\/unravel.properties \/usr\/local\/unravel\/logs\/ unravel \/etc\/init.d\/unravel_* \/etc\/init.d\/unravel_all.sh \nDuring initial install, a bundled database is used. This can be\nswitched to use an externally managed MySQL Do Host-Specific Post-Installation Actions For CDH, there are no\nhost-specific post-installation actions. 3. Configure Unravel Server (Basic\/Core Optional for CDH) Enable Optional Daemons Depending on your workload volume or kind of activity, you can\nenable optional daemons at this point. See Creating Multiple Workers for\nHigh Volume Data If Kerberos is Enabled: Add authentication for HDFS... or identify a\nprincipal and keytab for Unravel daemons to access HDFS and REST\nwhen Kerberos is enabled. Create Add properties for Kerberos in \n \/usr\/local\/unravel\/etc\/unravel.properties \ncom.unraveldata.kerberos.principal=unravel\/myhost.mydomain@MYREALM\ncom.unraveldata.kerberos.keytab.path=\/usr\/local\/unravel\/etc\/unravel.keytab You can verify the principal in a\nkeytab by using klist -kt KETYAB_FILE. unravel Run Unravel Daemons with\nCustom User If Sentry is Enabled: Add these permissions... Define your own alt principal with\nnarrow privileges. The alt principal can\nbe unravel rpm X \n \n \n Resource \n Principal \n Access \n Purpose \n \n \n hdfs:\/\/user\/spark\/applicationHistory \n Your alt principal \n read \n Spark event log \n \n \n hdfs:\/\/user\/spark\/spark2ApplicationHistory \n Your alt principal \n read \n Spark 2 event log \n \n \n hdfs:\/\/user\/history\/ \n Your alt principal \n read \n MapReduce logs \n \n \n hdfs:\/\/user\/history\/ \n Your alt principal \n read \n YARN aggregation folder \n \n \n hdfs:\/\/tmp\/logs \n Your alt principal \n read \n Obtain table partition sizes\nwith \"stat\" only \n \n \n hdfs:\/\/user\/hive\/warehouse Please see Configure Permission for\nUnravel daemons on CDH Sentry Secured Cluste You can find the principal by using\n 'klist -kt KEYTAB_FILE' If you are using KMS and HDFS\nencryption and are using the hdfs principal, you might need to\nadjust kms-acls.xml . If you are using \"JNI\" based groups\nfor HDFS (a setting in CM), then you will need to add \" export\nLD_LIBRARY_PATH=\/opt\/cloudera\/parcels\/CDH\/lib\/hadoop\/lib\/native\" to\n\/usr\/local\/unravel\/etc\/unravel.ext.sh Switch User Depending on your cluster security configuration, you will need\nto run the switch_to_user \n# sudo \/usr\/local\/unravel\/install_bin\/switch_to_user.sh x y where X Y switch_to_user Hive Metastore Access Hive metastore is accessed by Unravel server to analyze table\nusage in conjunction with Hive job instrumentation. Information is\ngathered using a Hive API that works very much like beeline\nconnections which leverage the jdbc database connection protocol.\nAs a quick-start approach, you can set Unravel to use the\nalready-defined 'hive' user that is also used by HiveServer2.\nAlternatively, a read-only metastore database user can be define.\nIf you want a custom user, then do the following steps for the\nparticular kind of database that is used for Hive metastore: Connect to the Hive metastore using the normal conversational\ninterface (mysql or psql, etc.) as an admin that can create new\nusers. Create a user, e.g., unravel Grant select on all table in the hive database. As the new user, use the conversational interface (mysql or\npsql, etc.) from the Unravel server to verify their access. Restart Unravel Server After the edits to\n com.unraveldata.login.admins \/usr\/local\/unravel\/etc\/unravel.properties echo # sudo \/etc\/init.d\/unravel_all.sh start\n# echo \"http:\/\/$(hostname -f):3000\/\" This completes the basic\/core configuration. 4. Log into Unravel Web UI Using a web browser, navigate to\n http:\/\/{UNRAVEL_HOST_IP} admin unraveldata UNRAVEL_HOST_IP. For the free trial version, use the Chrome web browser. Congratulations! Unravel Server is up and running. Unravel Web UI displays\ncollected data. For instructions on using Unravel Web UI, see the\n User Guide 5. Configure Unravel Server (Advanced Options) Enable Additional Data Collection\/Instrumentation Install the Unravel Sensor Parcel on gateway\/edge\/client nodes\nthat are used to submit Hive queries to push additional information\nto Unravel Server. For details, see Step 2: Install Unravel\nSensor Parcel on CDH+CM " }, 
{ "title" : "Step 2: Install Unravel Sensor Parcel on CDH+CM", 
"url" : "unravel-4-3/installation-guides/cloudera-distribution-including-apache-hadoop--cdh-,-with-cloudera-manager--cm-.html#UUID-6fc7d191-bb2a-f062-6fa9-5494db834124", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM) \/ Step 2: Install Unravel Sensor Parcel on CDH+CM", 
"snippet" : "Table of Contents Introduction 1. Obtain and Distribute the Parcel from Unravel Server 2. Put the Hive Hook JAR in AUX_CLASSPATH If Sentry is Enabled: 3. Configure the Gateway Automatic Deployment of Hive Instrumentation Set the hive-site.xml Snippet in Cloudera Manager, and Deploy the Hive Client C...", 
"body" : "\n Table of Contents \n \nIntroduction \n \n1. Obtain and Distribute the Parcel from Unravel Server \n \n2. Put the Hive Hook JAR in AUX_CLASSPATH \n If\nSentry is Enabled: \n \n3. Configure the Gateway Automatic Deployment of Hive\nInstrumentation \n \nSet the hive-site.xml Snippet in Cloudera Manager, and Deploy the\nHive Client Configuration to Gateways \n Check\nUnravel Web UI \n \n4. Configure the Gateway Automatic Deployment of Spark\nInstrumentation \n \n5. Optional - Configure YARN - MapReduce (MR) JVM Sensor\nCluster-Wide \n Set\nin Cloudera Manager \n \n6. (Optional) Advanced Configuration \n Troubleshooting \n References Introduction This topic explains how to install the Unravel Sensor parcel on\nCDH clusters using Cloudera Manager (CM). The parcel includes Hive\nHook and Spark instrumentation JARs. Hive Hook is used to collect\ninformation about Hive queries in Hadoop. The Spark instrumentation\nJARs measure Spark job performance. These instructions apply to Unravel Sensor 4.3 Before following these instructions, follow the steps in\n Step 1: Install Unravel Server on CDH+CM \n Workflow Summary Obtain and distribute the parcel from Unravel Server. Put the Hive Hook JAR in AUX_CLASSPATH Configure the gateway automatic deployment of Hive\ninstrumentation. Configure the gateway automatic deployment of Spark\ninstrumentation. text and text with brackets ( {\n} ), except where otherwise noted, indicate where you must\nsubstitute your particular values for the text. HIGHLIGHTED When Active Directory Kerberos is used, UNRAVEL_HOST_IP To Upgrade the Unravel Sensor Check the UNRAVEL_SENSOR If an upgrade is available complete steps\n3 through 5 1. Obtain and Distribute the Parcel from Unravel Server In Cloudera Manager (CM), go to the Parcels ) on the top of the page. Click Configuration Parcel\nSettings In the Remote Parcel Repository URLs Parcel Settings + Add http:\/\/{UNRAVEL_HOST_IP}:3000\/parcels\/cdh{X.Y}\/ X.Y UNRAVEL_HOST_IP unravel_lr UNRAVEL_HOST_IP Click Save Click Check for New Parcels On the Parcels Location In the list of Parcel Names UNRAVEL_SENSOR Download Click Distribute If you have an old parcel from Unravel, you can deactivate it\nnow. Then click Activate 2. Put the Hive Hook JAR in AUX_CLASSPATH In Cloudera Manager, for the target cluster, click\n Hive Configuration hive-env In Gateway Client Environment Advanced Configuration\nSnippet (Safety Valve) hive-env.sh \nAUX_CLASSPATH=${AUX_CLASSPATH}:\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/unravel_hive_hook.jar In Cloudera Manager, click YARN Configuration hadoop-env In Gateway Client Environment Advanced Configuration\nSnippet (Safety Valve) hadoop-env.sh no\nsubsitutions \nHADOOP_CLASSPATH=${HADOOP_CLASSPATH}:\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/unravel_hive_hook.jar If Sentry is Enabled: Sentry commands may also be needed to enable access to the Hive\nHook JAR file. Grant privileges on the JAR files to the roles that\nrun hive queries. Log into Beeline as user hive SQL GRANT {ROLE} \n# GRANT ALL ON URI 'file:\/\/\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/unravel_hive_hook.jar' TO ROLE {ROLE} 3. Configure the Gateway Automatic Deployment of Hive Instrumentation Use Cloudera Manager to deploy the hive-site.xml \/usr\/local\/unravel\/hive-hook\/hive-site.xml.snip On a multi-host Unravel\nServer deployment, use\nhost2's \/usr\/local\/unravel\/hive-hook\/hive-site.xml.snip Set the hive-site.xml Snippet in Cloudera Manager, and Deploy the Hive Client Configuration to Gateways In Cloudera Manager (CM): Go to Hive service. Select the Configuration Search for hive-site.xml Add the xml snippet to Hive\nClient Advanced Configuration Snippet for\n hive-site.xml View as XML If cluster has been configured with \"Cloudera Navigator\"; the\n hive.exec.post.hooks hive.exec.post.hooks \n com.cloudera.navigator.audit.hive.HiveExecHookContext,org.apache.hadoop.hive.ql.hooks.LineageLogger,\ncom.unraveldata.dataflow.hive.hook.HivePostHook The \"Hive Client Advanced\nConfiguration Snippet for hive-site.xml\" should only have the\nUnravel class. IMPORTANT! \nHowever, the \"HiveServer2 Advanced Configuration Snippet for\nhive-site.xml\" should have all 3 classes: 2 from Navigator and 1\nfrom Unravel. Add the xml snippet to HiveServer2 Advanced\nConfiguration Snippet for hive-site.xml View as XML Save the changes with optional comment \"Unravel snippet in\n hive-site.xml \" Perform action Deploy Hive Client\nConfiguration ) or by using the Actions Restart the Hive service. (Cloudera Manager will specify a\nrestart which is not necessary for activating these changes. You\nmay act on CM's recommendation at a later time. ) Again, monitor the situation to see if all Hive queries are\nfailing with a class not found or permission problems. If\nthey are failing hive-site.xml Troubleshooting Check Unravel Web UI If queries are running fine and appearing in Unravel Web UI,\nthen you are done. 4. Configure the Gateway Automatic Deployment of Spark Instrumentation In Cloudera Manager, select the target cluster, then select the\nSpark service. Select Configuration Search for \" spark-defaults In the Spark\nClient Advanced Configuration Snippet (Safety Valve) for\nspark-conf\/spark-defaults.conf On a\nmulti-host Unravel Server deployment, use the fully qualified DNS\nor logical host2 for UNRAVEL_HOST_IP Copy the text below and paste it into the Cloudera Manager's\n Spark Client Advanced Configuration Snippet (Safety\nValve) spark-defaults.conf spark-conf\/ UNRAVEL_HOST_IP SPARK_VERSION has\nthe following possible values: SPARK_VERSION_X.Y spark-1.3 spark-1.5 spark-1.6 spark-2.0 spark- 2.2 spark- 2.3 spark.unravel.server.hostport={UNRAVEL_HOST_IP}:4043 \nspark.driver.extraJavaOptions=-javaagent:\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/btrace-agent.jar=config=driver,libs={SPARK_VERSION-X.Y}\nspark.executor.extraJavaOptions=-javaagent:\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/btrace-agent.jar=config=executor,libs={SPARK_VERSION-X.Y}\nspark.eventLog.enabled=true 5. Save changes. 6. Deploy client configuration by\nclicking the deploy glyph ( Actions Monitor the situation to see if all Spark queries are failing\nwith a class not found or permission problems. If they are\nfailing spark-defaults.conf 5. Optional - Configure YARN - MapReduce (MR) JVM Sensor Cluster-Wide Set in Cloudera Manager In Cloudera Manager (CM): Go to YARN Select the Configuration Search for ApplicationMaster Java Opts\nBase ). Make sure that \"-\"\nis a minus sign. You need to modify the value of UNRAVEL_HOST_IP \n-javaagent:\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/btrace-agent.jar=libs=mr -Dunravel.server.hostport={UNRAVEL_HOST_IP}:4043 Search for MapReduce Client Advanced\nConfiguration Snippet (Safety Valve) for mapred-site.xml Enter following xml four\nblock properties snippet to Gateway Default\nGroup View as XML \n<property><name>mapreduce.task.profile<\/name><value>true<\/value><\/property>\n<property><name>mapreduce.task.profile.maps<\/name><value>0-5<\/value><\/property>\n<property><name>mapreduce.task.profile.reduces<\/name><value>0-5<\/value><\/property>\n<property><name>mapreduce.task.profile.params<\/name><value>-javaagent:\/opt\/cloudera\/parcels\/UNRAVEL_SENSOR\/lib\/java\/btrace-agent.jar=libs=mr -Dunravel.server.hostport={UNRAVEL_HOST_IP}:4043<\/value><\/property> 6. Save changes. 7. Deploy client configuration by\nclicking the deploy glyph ( Actions 8. Cloudera Manager will specify a\nrestart which is not necessary to effect these changes.\n(click Restart Stale Services Monitor the situation and you should see in Unravel UI a\nResource Usage tab showing you mappers and reducers when you view the Application page for any\ncompleted MRjob.\nRestart is important for MR sensor to be picked up by queries\nsubmitted via Hiveserver2. 6. (Optional) Advanced Configuration Configuration for high volume data: see Creating Multiple Workers for\nHigh Volume Data Add LDAP users: see Integrating LDAP\nAuthentication for Unravel Web UI Troubleshooting \n \n \n \n Symptom \n \n Problem \n \n Remedy \n \n \n hadoop fs -ls\n\/user\/unravel\/HOOK_RESULT_DIR\/ \nshows directory does not exist \n Unravel Server RPM is not yet installed, or Unravel Server RPM is installed on a different HDFS cluster,\nor HDFS home directory for Unravel does not exist, or kerberos\/sentry actions are needed \n Install Unravel RPM on Unravel service host: \n sudo rpm -U unravel*.rpm* \n OR \nVerify that unravel \/user\/unravel\/ \n \n error for\n ClassNotFound com.unraveldata.dataflow.hive.hook.HivePreHook \n Unravel hive hook JAR was not found in in\n $HIVE_HOME\/lib\/ \n Check whether UNRAVEL_SENSOR parcel was distributed and\nactivated in CM. \n OR \nPut the Unravel hive-hook JAR corresponding to HIVE_VER JAR_DEST \n cd \/usr\/local\/unravel\/hive-hook\/; \n cp unravel-hive-HIVE_VER*hook.jar JAR_DEST References \nsee Creating Permanent Functions. {+} http:\/\/www.cloudera.com\/documentation\/enterprise\/5-3-x\/topics\/cm_mc_hive_udf.html#concept_nc3_mms_lr_unique_2+ " }, 
{ "title" : "Step 3: Enable Impala APM", 
"url" : "unravel-4-3/installation-guides/cloudera-distribution-including-apache-hadoop--cdh-,-with-cloudera-manager--cm-.html#UUID-9f93973b-fcd0-f103-3736-d7755420d2cc", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Cloudera Distribution Including Apache Hadoop (CDH), with Cloudera Manager (CM) \/ Step 3: Enable Impala APM", 
"snippet" : "Introduction This topic explains how to configure Unravel Server to retrieve Impala query data from either ClouderaManager (CM) or Impala daemons ( impalad Before following these instructions, follow the steps in Step 1: Install Unravel Server on CDH+CM By default, the ImpalaSensor task is enabled. ...", 
"body" : "Introduction This topic explains how to configure Unravel Server to retrieve\nImpala query data from either ClouderaManager (CM) or Impala\ndaemons ( impalad Before following these instructions, follow the steps in\n Step 1: Install Unravel Server on CDH+CM By default, the ImpalaSensor task is enabled. If user wishes to\ndisable ImpalaSensor, specify the following option\nin \/usr\/local\/unravel\/etc\/unravel.properties com.unraveldata.sensor.tasks.disabled=iw \n Workflow Summary If you want Unravel Server to retrieve Impala query data from\nClouderaManager, start at Using CM as the Data\nSource If you want Unravel Server to retrieve Impala query data from\nImpala daemons, start at Using Impalad as the Data\nSource Using CM as the Data Source In order to this you need to\nadd com.unraveldata.data.source=cm \/usr\/local\/unravel\/etc\/unravel.properties \/usr\/local\/unravel\/etc\/unravel.properties \n \n \n Property \n Description \n \n com.unraveldata.cloudera.manager.url \n CM internal URL. Must start with\n http:\/\/ \n \n com.unraveldata.cloudera.manager.port \n (Optional) CM port number. You only need to specify this if your\nCloudera Manager is not on port 7180. \n \n com.unraveldata.cloudera.manager.username \n CM username \n \n com.unraveldata.cloudera.manager.password \n CM password \n \n com.unraveldata.cloudera.manager.version \n (Optional) CM version. You only need to specify this if your\nCloudera Manager is earlier than 5.8.0. : Replace the dot “.” in the version number\nwith underscore “_”. In other words, if you have version 5.7.x,\nthen set com.unraveldata.cloudera.manager.version=5_7_0. Note \n \n com.unraveldata.cloudera.manager.cluster.name.list \n A comma-separated list of cluster names \n \n \ncom.unraveldata.cloudera.manager.service.impala.name \n (Optional) You only need to specify this if the Impala service\nname is not defaulted as \" impala For example: com.unraveldata.data.source=cm\ncom.unraveldata.cloudera.manager.url=http:\/\/mycm.somewhere.secret\ncom.unraveldata.cloudera.manager.port=9997\ncom.unraveldata.cloudera.manager.username=mycmname\ncom.unraveldata.cloudera.manager.password=mycmpassword\ncom.unraveldata.cloudera.manager.version=5_7_0\ncom.unraveldata.cloudera.manager.cluster.name.list=cluster1,cluster2,cluster5\ncom.unraveldata.cloudera.manager.service.impala.name=myimpalaservicename Hints: To find out the cluster name: {cm_url}:{cm_port}\/api\/v13\/clusters\/ To find out the service name: \n{cm_url}:{cm_port}\/api\/v13\/clusters\/{cluster_name}\/services\/\n\n Substitute your particular values for bracketed ClouderaManager\n(CM) properties, i.e., {cm_port} Using Impalad as the Data Source Use this option if you want to import data from\n impalad impalad https:\/\/www.cloudera.com\/documentation\/enterprise\/5-2-x\/topics\/impala_security_webui.html https:\/\/www.cloudera.com\/documentation\/enterprise\/5-3-x\/topics\/impala_webui.html CM as\nthe data source In order to use impalad as the data source you need to\nadd com.unraveldata.data.source=impalad \/usr\/local\/unravel\/etc\/unravel.properties impalad \n \n \n Property \n Description \n \n com.unraveldata.data.source \n Set this to impalad \n \n com.unraveldata.impalad.nodes \n A comma-separated list of impalad IP:port,IP:port,IP:port For example: com.unraveldata.data.source=impalad\ncom.unraveldata.impalad.nodes=IP:port,IP:port,IP:port References \n https:\/\/www.cloudera.com\/documentation\/cdh\/5-1-x\/Impala\/Installing-and-Using-Impala\/ciiu_install.html \n https:\/\/www.cloudera.com\/documentation\/enterprise\/5-2-x\/topics\/impala_security_webui.html \n https:\/\/www.cloudera.com\/documentation\/enterprise\/5-3-x\/topics\/impala_webui.html " }, 
{ "title" : "Hortonworks Data Platform (HDP)", 
"url" : "unravel-4-3/installation-guides/hortonworks-data-platform--hdp-.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Hortonworks Data Platform (HDP)", 
"snippet" : "This guide is compatible with: HDP 2.2-2.6...", 
"body" : " This guide is compatible with: HDP 2.2-2.6 " }, 
{ "title" : "Ordered Steps", 
"url" : "unravel-4-3/installation-guides/hortonworks-data-platform--hdp-.html#UUID-a320d06e-3095-d1ae-65b3-e6bcb5251131_id_HortonworksDataPlatformHDP-OrderedSteps", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Hortonworks Data Platform (HDP) \/ Ordered Steps", 
"snippet" : "Step 1: Install Unravel Server on HDP Step 2: Enable Additional Data Collection \/ Instrumentation for HDP...", 
"body" : " \n Step 1: Install Unravel Server on HDP \n Step 2: Enable Additional Data Collection \/ Instrumentation\nfor HDP " }, 
{ "title" : "Step 1: Install Unravel Server on HDP", 
"url" : "unravel-4-3/installation-guides/hortonworks-data-platform--hdp-.html#UUID-18633110-9981-9339-796a-55c4fc3aeb57", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Hortonworks Data Platform (HDP) \/ Step 1: Install Unravel Server on HDP", 
"snippet" : "Table of Contents Introduction Pre-Installation Check Platform Compatibility Hardware Software Access Permissions Network 1. Configure the Host Machine Allocate a Cluster Gateway\/Edge\/Client Host with HDFS Access 2. Install the Unravel Server RPM on the Host Machine Get the Unravel Server RPM Make s...", 
"body" : "\n Table of Contents \n Introduction \n Pre-Installation\nCheck \n Platform\nCompatibility \n Hardware \n Software \n Access\nPermissions \n Network \n 1.\nConfigure the Host Machine \n \nAllocate a Cluster Gateway\/Edge\/Client Host with HDFS\nAccess \n \n2. Install the Unravel Server RPM on the Host Machine \n Get the\nUnravel Server RPM \n Make\nsymlinks if required \n Install\nthe Unravel Server RPM \n \nDo Host-Specific Post-Installation Actions \n \n3. Configure Unravel Server (Basic\/Core Options) \n Enable\nOptional Daemons \n Modify\nunravel.properties \n If Kerberos\nis Enabled: \n If Ranger is\nEnabled: \n Disable\nImpala Sensor: \n \n4. Convert Your Unravel Installation to HDP \n \nRun the following commands on Unravel Server: \n Switch\nUser \n Restart\nUnravel Server \n 5. Log\ninto Unravel Web UI \n Congratulations! \n \n6. Configure Unravel Server (Advanced Options) \n \nEnable Additional Data Collection\/Instrumentation Introduction This topic explains how to\ndeploy Unravel Server 4.0 on HDP. These instructions\napply to Unravel Server 4.0. For older versions of Unravel Server,\ncontact Unravel Support. \n Workflow Summary Pre-installation check Configure the host machine. Install the Unravel Server RPM on the host machine. Configure Unravel Server (basic\/core options). Log into Unravel Web UI. (Optional) Configure Unravel Server (advanced options). Pre-Installation Check The following installation requirements must be met for\nsuccessful installation of Unravel. Platform Compatibility HDP 2.2-2.6 Hadoop 1.x - 2.x Kafka 0.9-1.0 (Apache ver. equiv.) Kerberos Hive 0.9.x - 1.2.x Spark 1.3.x - 2.2.x Hardware Architecture: x86_64 Cores: 8 RAM: 64GB minimum, 128GB for medium volume (>25,000 jobs per\nday), 256GB for high volume (>50,000 jobs per day) Disk: \/usr\/local\/unravel Disk: \/srv\/unravel For 60,000+ MR jobs per day, two or more gateway\/edge nodes are\nrecommended (\"multi-host Unravel\") Software Operating System: RedHat\/Centos 6.4 - 7.4 installed libaio.x86_64 (or disabled) should be set in\n SELINUX=permissive \/etc\/selinux\/config HDFS+Hive+YARN client\/gateway, Hadoop and Hive commands in\n PATH If Spark is in use, Spark client gateway You need to register edge node to Ambari LDAP (AD or Open LDAP) compatible for Unravel Web UI user\nauthentication (Open signup by default) On Unravel Edge-node server, please do\nnot Access Permissions If Kerberos is in use, a keytab for principal is required for\naccess to:\n Access to YARN’s “done dir” in HDFS Access to YARN’s log aggregation directory in HDFS Access to Spark event log directory in HDFS Access to file sizes under HIve warehouse directory Access to YARN Resource Manager REST API principal needs right to find out which RM is active JDBC access to the Hive Metastore (read-only user is\nsufficient) Application Timeline Server (ATS)\nread-only The RUN_AS user must be\nincluded in yarn.admin.acl and\n tez.am the cluster uses kerberos\nfor authentication or the resource manager has\nbeen configured in high availability mode, Network Port 3000 from users and entire cluster to Unravel Web UI HDFS ports open from Hadoop cluster to Unravel Server(s) For YARN, Hive Metadata DB port open to Unravel Server(s) for\npartition reporting UDP and TCP port 4043 open from entire cluster to Unravel\nServer(s) For Oozie, port 11000 open from Unravel Server(s) to the Oozie\nserver Resource Manager (RM) port 8032 from Unravel Server(s) to the\nRM server(s) ATS port 8188 from Unravel Servers(s) to ATS server(s) Port 4020, 4176, 4181 through 4189, 3316, 4091 must be\navailable for localhost communication between Unravel daemons\nor Unravel servers (if multi-host Unravel\ninstallation) 1. Configure the Host Machine Allocate a Cluster Gateway\/Edge\/Client Host with HDFS Access For HDP, use Ambari Web UI to\ncreate a Gateway node configuration. 2. Install the Unravel Server RPM on the Host Machine Get the Unravel Server RPM See Download Unravel\nSoftware Make symlinks if required If you want the two disk areas used by Unravel to be on\ndifferent volumes, you can make symlinks to specific areas before\ninstalling (or do\na mv symlink \/usr\/local\/unravel \/srv\/unravel Install the Unravel Server RPM # sudo rpm -U unravel-4.*.x86_64.rpm*\n# \/usr\/local\/unravel\/install_bin\/await_fixups.sh The precise filename can vary,\ndepending on how it was fetched or copied. The\n rpm rpm -U Run the\nspecified await_fixups.sh await_fixups.sh Done The installation creates \/usr\/local\/unravel\/ unravel \/srv\/unravel\/ \nThe master configuration file is\nin \/usr\/local\/unravel\/etc\/unravel.properties \/usr\/local\/unravel\/logs\/ unravel \/etc\/init.d\/unravel_* \/etc\/init.d\/unravel_all.sh \nThe RPM installation also creates an HDFS directory for Hive Hook\ninformation collection. \nDuring initial install, a bundled database is used. This can be\nswitched to use an externally managed MySQL for production. (The\nbundled database root mysql password will be stored\nin \/root\/unravel.install.include Do Host-Specific Post-Installation Actions For HDP, there are no\nhost-specific post-installation actions. 3. Configure Unravel Server (Basic\/Core Options) Enable Optional Daemons Depending on your workload volume or kind of activity, you can\nenable optional daemons at this point. See Creating Multiple Workers for\nHigh Volume Data Modify unravel.properties Open \/usr\/local\/unravel\/etc\/unravel.properties vi \n# sudo vi \/usr\/local\/unravel\/etc\/unravel.properties Edit the values in unravel.properties \n \n \n Property \n Description \n Example Values \n \n \n com.unraveldata.advertised.url \n Defines the Unravel Server URL\nfor HTTP traffic. \n \n http:\/\/LAN_DNS:3000 \n \n \n com.unraveldata.customer.organization \n Identifies your installation\nfor reporting purposes. \n \n Company_and_org \n \n com.unraveldata.tmpdir \n Location where Unravel's temp\nfile will reside \n \/srv\/unravel\/tmp \n \n \n com.unraveldata.history.maxSize.weeks \n Sets retention for search\ndata. \n \n 26 \n \n \n com.unraveldata.job.collector.done.log.base \n Only modifiable through Unravel Web UI's\nconfiguration wizard. \n \/mr-history\/done \n \n \n com.unraveldata.job.collector.log.aggregation.base \n Only modifiable through Unravel Web UI's\nconfiguration wizard. \n \/app-logs\/*\/logs\/ \n \n \n com.unraveldata.login.admins \n Defines the usernames that can\naccess Unravel Web UI's admin pages. Default is\n admin \n \n admin \n \n \n com.unraveldata.s3.batch.monitoring.interval.sec \n .\nDefines the monitoring frequency. Default is 300 seconds (5\nminutes). Set this property to 60 for lower latency. Optional \n \n 120 \n \n \n com.unraveldata.spark.eventlog.location \n Where to find Spark event\nlogs \n \nhdfs:\/\/\/user\/spark\/applicationHistory\/,hdfs:\/\/\/user\/spark\/sparkApplicationHistory\/,hdfs:\/\/\/user\/spark\/spark2ApplicationHistory\/ \n \n \n yarn.resourcemanager.webapp.address \n YARN resource manager\nweb address URL \n http:\/\/example.localdomain:8088 \n \n \n oozie.server.url \n Oozie URL \n http:\/\/example.localdomain:11000\/oozie If\nKerberos is Enabled: Add authentication for HDFS... Create or identify a principal and keytab for Unravel daemons to\naccess HDFS and REST when Kerberos is enabled. Add properties for Kerberos in \/usr\/local\/unravel\/etc\/unravel.properties \ncom.unraveldata.kerberos.principal=unravel\/myhost.mydomain@MYREALM\ncom.unraveldata.kerberos.keytab.path=\/usr\/local\/unravel\/etc\/unravel.keytab You can verify the principal in a\nkeytab by using properties klist -kt\nKEYTAB_FILE . Run Unravel Daemons with\nCustom User If\nRanger is Enabled: Add these permissions... Define your own alt principal with\nnarrow privileges. The alt principal can be unravel rpm X \n \n \n Resource \n Principal \n Access \n Purpose \n \n \n hdfs:\/\/spark-history \n Your alt principal \n read+execute \n Spark event log \n \n hdfs:\/\/spark2-history \n Your alt principal \n read+execute \n Spark2 event log \n \n \n hdfs:\/\/mr-history\/done \n Your alt\nprincipal \n read+execute \n MapReduce logs \n \n \n hdfs:\/\/app-logs \n Your alt\nprincipal \n read+execute \n YARN aggregation folder \n \n \n hdfs:\/\/apps\/hive\/warehouse (default value\nof hive.metastore.warehouse.dir) \n Your alt\nprincipal \n read+execute \n Obtain table partition\nsizes \n \n Hive Metastore database\nGRANT \n hive \n read+execute \n Hive table information \nDisable Impala Sensor: Impala is not officially supported on HDP clusters therefore you\nshould disable the ImpalaSensor by modifying\nthe \/usr\/local\/unravel\/etc\/unravel.properties \nOpen unravel.properties com.unraveldata.sensor.tasks.disabled com.unraveldata.sensor.tasks.disabled=iw 4. Convert Your Unravel Installation to HDP Run the following commands on Unravel Server: # sudo \/etc\/init.d\/unravel_all.sh stop\n# sudo \/usr\/local\/unravel\/install_bin\/switch_to_hdp.sh Note: This change\nwill stick after later RPM upgrades; it does not need to be done\neach time. Switch User Depending on your cluster security configuration, you will need\nto run the switch_to_user \n# sudo \/usr\/local\/unravel\/install_bin\/switch_to_user.sh x y where X Y switch_to_user Restart Unravel Server After edits to com.unraveldata.login.admins \/usr\/local\/unravel\/etc\/unravel.properties echo UNRAVEL_HOST_IP # sudo \/etc\/init.d\/unravel_all.sh start\n# sleep 60\n# echo \"http:\/\/$(hostname -f):3000\/\" This completes the basic\/core configuration. 5. Log into Unravel Web UI Using a web browser, navigate to\n http:\/\/{UNRAVEL_HOST_IP} admin\" \"unraveldata For the free trial version, use the Chrome web browser. Congratulations! Unravel Server is up and running. Unravel Web UI displays\ncollected data. For instructions on using Unravel Web UI, see the\n User Guide 6. Configure Unravel Server (Advanced Options) Enable Additional Data Collection\/Instrumentation Install the Unravel Sensor Parcel on gateway\/edge\/client nodes\nthat are used to submit Hive queries to push additional information\nto Unravel Server. For details, see Part 2 (Optional): Enable\nAdditional Data Collection \/ Instrumentation for HDP " }, 
{ "title" : "Step 2: Enable Additional Data Collection \/ Instrumentation for HDP", 
"url" : "unravel-4-3/installation-guides/hortonworks-data-platform--hdp-.html#UUID-a2bcddfc-ab84-a4dd-dc7f-130c72d54ecb", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ Hortonworks Data Platform (HDP) \/ Step 2: Enable Additional Data Collection \/ Instrumentation for HDP", 
"snippet" : "Introduction This topic explains how to configure Unravel Sensor for Tez ( unravel_us text and text with brackets ( { } ) indicate where you must substitute your particular values for the text. HIGHLIGHTED must be a fully qualified DNS or an IP address. UNRAVEL_HOST_IP 1. Convert Your Unravel Instal...", 
"body" : "Introduction This topic explains how to\nconfigure Unravel Sensor for Tez\n( unravel_us text and\ntext with brackets ( { } ) indicate where you must substitute your\nparticular values for the text. HIGHLIGHTED must be\na fully qualified DNS or an IP address. UNRAVEL_HOST_IP 1. Convert Your Unravel Installation to HDP. # sudo \/etc\/init.d\/unravel_all.sh stop\n# sudo \/usr\/local\/unravel\/install_bin\/switch_to_hdp.sh Note: This change\nremains after RPM upgrades. 2. Update Site-Specific HDP Properties in unravel.properties Add these properties\n to\/usr\/local\/unravel\/etc\/unravel.properties \n \n \n Property \n Description \n Default Value \n \n \n com.unraveldata.yarn.timeline-service.webapp.address \n The http address of the Timeline service web\napplication \n \n http:\/\/localhost \n \n \n com.unraveldata.yarn.timeline-service.port \n Timeline service port \n 8188 For example, \ncom.unraveldata.yarn.timeline-service.webapp.address=http:\/\/172.16.1.101\ncom.unraveldata.yarn.timeline-service.port=8188 Open\n \/usr\/local\/unravel\/etc\/unravel.properties switch_to_hdp.sh If you are using Spark1 and Spark2 you must com.unraveldata.spark.eventlog.location com.unraveldata.spark.eventlog.location =hdfs:\/\/\/spark1-history\/, \/\/ Repoint Unravel application logs directory\ncom.unraveldata.job.collector.done.log.base=\/mr-history\/done\ncom.unraveldata.job.collector.log.aggregation.base=\/app-logs\/*\/logs\/\ncom.unraveldata.spark.eventlog.location=hdfs:\/\/\/spark-history\/\n \n\/\/ Add Hive Metastore database information for Unravel Hive Config \njavax.jdo.option.ConnectionURL=jdbc:mysql:\/\/{hostname}:3306\/{database_name} \njavax.jdo.option.ConnectionDriverName=com.mysql.jdbc.Driver\njavax.jdo.option.ConnectionUserName={HiveMetastoreUserName} \njavax.jdo.option.ConnectionPassword={HiveMetastorePassword} Log into Ambari Web UI (AWU) to verify the above properties\nhave been set correctly in unravel.properties On the\nleft-hand side of AWU's dashboard, click\n MapReduce2 Configs Advanced Advanced mapred-site Verify com.unraveldata.job.collector.done.log.base mapreduce.jobhistory.done-dir. On the left-hand side of AWU's\ndashboard, click YARN Configs Advanced Node Manager Verify com.unraveldata.job.collector.done.log. aggregation.base yarn.nodemanager.remote-app=log-dir On the\nleft-hand side of AWU's dashboard, click\n Hive Configs Advanced Hive Metastore Verify javax.jdo.option.ConnectionURL Database\nHost Database URL Verify javax.jdo.option.ConnectionDriverName JDBC Driver\nClass Verify javax.jdo.option.ConnectionUserName Database Username 3. Start Unravel Server Note: Unravel must\nbe up for the next step to complete. # sudo \/etc\/init.d\/unravel_all.sh start 4. Install Unravel Hive Hook and Spark Sensor Onto HDP Servers Install Unravel Hive Hook and Spark\nSensor onto HDP servers (JAR files) as follows (substitute correct\nfully qualified host name or IP address for UNRAVEL_HOST_IP Login as root and ensure\n wget \n# \/usr\/local\/unravel\/install_bin\/unraveldata-clients\/unravel_hdp_setup.sh From Unravel server (eg. edge node)\nrun on each server that will use instrumentation. Be sure to substitute valid values. has the following possible\nvalues: SPARK_VERSION_X.Y spark-1.3 spark-1.5 spark-1.6 spark-2.0 2.2.0 \n HIVE_VERSION -\nmust be a Hive version that Unravel Server supports: either\n1.2.0 or 0.13.0. Be sure to use either of\nthese values in exactly this\nformat. # yum install -y wget\n# cd \/usr\/local\/unravel\/install_bin\/unraveldata-clients\/\n# sudo .\/unravel_hdp_setup.sh install -y --unravel-server {UNRAVEL_HOST_IP}:3000 --hive-version {HIVE_VERSION} --spark-version {SPARK_VERSION} Files are installed locally on the edge node under: \n \/usr\/local\/unravel_client (Hive hook jar) \n \/usr\/local\/unravel-agent\/jars\/ (Resource metrics sensor\njars) these two directories on all nodes in the\ncluster (worker \/ edge \/ master). In all cases, instrumented nodes\nmust be able to open port 4043 of Unravel Server\n( Manually copy host2 5. Add Unravel Hive Hook hive-site Settings to All of HDP's Servers in the Cluster Using AWU Completion of this step requires a restart of all affected Hive\nservices in Ambari UI. In AWU, on the left-hand side, click\n Hive Configs Advanced Custom\nhive-site Add Property Bulk property add mode. \nhive.exec.driver.run.hooks=com.unraveldata.dataflow.hive.hook.HiveDriverHook \ncom.unraveldata.hive.hdfs.dir=\/user\/unravel\/HOOK_RESULT_DIR \ncom.unraveldata.hive.hook.tcp=true \ncom.unraveldata.host={add unravel gateway internal IP hostname} \n \n\/\/ Find below properties as it may already exists, concatenate it with a comma & no spaces\nhive.exec.pre.hooks=com.unraveldata.dataflow.hive.hook.HivePreHook \nhive.exec.post.hooks=com.unraveldata.dataflow.hive.hook.HivePostHook \nhive.exec.failure.hooks=com.unraveldata.dataflow.hive.hook.HiveFailHook If LLAP is enabled copy the above\nsettings in Custom hive-interactive-site Manual edit hive-site.xml (no AWU) file is located at\n hive-site.xml \/etc\/hive\/conf\/ Add AUX_CLASSPATH hive-env In AWU, on the left-hand side, click Hive Configs Advanced Advanced\nhive-env Next, inside the Advanced\nhive-env \nexport AUX_CLASSPATH=${AUX_CLASSPATH}:\/usr\/local\/unravel_client\/unravel-hive-1.2.0-hook.jar If LLAP is enabled copy above line of\ncode into Advanced hive-interactive-env You can manually edit hive-env.sh without using\nAWU. The hive-env.sh \/etc\/hive\/conf\/ Add HADOOP_CLASSPATH hadoop-env In AWU, on the left-hand side, click HDFS Configs Advanced Advanced\nhadoop-env Next, inside the\n hadoop-env export\nHADOOP_CLASSPATH \nexport HADOOP_CLASSPATH=${HADOOP_CLASSPATH}:\/usr\/local\/unravel_client\/unravel-hive-1.2.0-hook.jar 6. Optionally for Tez, Enable Unravel Tez Instrumentation on all of HDP's Services in the Cluster Completion of this step requires a restart of all affected Hive\nservices in Ambari UI. Confirm that hive-execution.engine is\nset to tez. set hive.execution.engine=tez; Using the Ambari Web UI (AWU), configure the Btrace agent for\nTez: Append -javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=mr,config=tez\n-Dunravel.server.hostport=UNRAVEL_HOST_IP:4043 .launch.cmd-opts tez.am tez.task.launch.cmd-opts Restart the affected\ncomponent(s). The screenshot below illustrates this change. In a Kerberos environment we will need to\nmodify .view-acls tez.am 7. Optionally for Spark on YARN, Enable Unravel Spark Instrumentation on All of HDP's Servers in the Cluster Completion of this step requires a restart of all affected Spark\nservices in Ambari UI. Be sure to substitute valid values.for UNRAVEL_HOST_IPX SPARK_VERSION_X.Y. \n has the following possible\nvalues: SPARK_VERSION_X.Y spark-1.3 spark-1.5 spark-1.6 spark-2.0 spark- 2.2 spark- 2.3 Add Spark properties into AWU's Custom\nspark-defaults In AWU, on the left-hand side, click Spark Configs Custom\nspark-defaults Inside Custom spark-defaults Add\nProperty Bulk property add mode spark.unravel.server.hostport={UNRAVEL_HOST_IP}:4043\nspark.driver.extraJavaOptions=-javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=config=driver,libs=spark-{SPARK_VERSION_X.Y}\nspark.executor.extraJavaOptions=-javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=config=executor,libs=spark-{SPARK_VERSION_X.Y} \nspark.eventLog.enabled=true You can manually edit spark-defaults.conf without\nusing AWU. The default location for spark-defaults.conf \/usr\/hdp\/current\/SPARK_VERSION_X.Y The cluster only has one spark 1.X version: \/usr\/hdp\/current\/spark-client\/conf For spark 2.X version: \/usr\/hdp\/current\/spark2-client\/conf 8. Optionally for MapReduce2 (MR) JVM Sensor Cluster-Wide Completion of this step will require a\nrestart of all affected HDFS, MAPREDUCE2, YARN and\nHIVE services in Ambari UI. In AWU, on the left-hand\nside, click MapReduce2 Configs Advanced Advancedmapred-site Search for MR AppMaster Java Heap\nSize current.yarn.app.mapreduce.am.command-opts \n-javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=mr -Dunravel.server.hostport={UNRAVEL_HOST_IP}:4043 On\nthe top notification banner, click Save In AWU, on the left-hand side, click\n MapReduce2 Configs Advanced Custom mapred-site: Inside Custom mapred-site Add Property : Bulk property add mode On the top notification banner, click\nSave mapreduce.task.profile=true\nmapreduce.task.profile.maps=0-5\nmapreduce.task.profile.reduces=0-5\nmapreduce.task.profile.params=-javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=mr -Dunravel.server.hostport=UNRAVEL_HOST_IP:4043 Notice that in this code block, the\nblank lines separate single full lines of text that are wrapped due\nto length. Also, ensure you replace UNRAVEL_HOST_IP You can manually edit mapred-site.xml without\nusing AWU. The mapred-site.xml \/etc\/hadoop\/conf\/ 9. Optionally for YARN If yarn.acl.enable=true or yarn.acl.enable=false, (set to * to allow\naccess to everyone) yarn.admin.acl=userName 10. Confirm that Unravel Web UI Shows Tez Data Run\n \/usr\/local\/unravel\/install_bin\/hive_test_simple.sh hive.execution.engine=tez Check Unravel Web UI for Tez\ndata. For instructions, see Tez Application Manager Unravel Web UI may take a few seconds to load Tez\ndata. " }, 
{ "title" : "MapR", 
"url" : "unravel-4-3/installation-guides/mapr.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ MapR", 
"snippet" : "This guide is compatible with MapR 5.1, 5.2, 6.0.1...", 
"body" : " This guide is compatible with MapR 5.1, 5.2, 6.0.1 " }, 
{ "title" : "Ordered Steps", 
"url" : "unravel-4-3/installation-guides/mapr.html#UUID-172b4948-3c89-bd0e-f4a7-9f325749a86f_id_MapR-OrderedSteps", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ MapR \/ Ordered Steps", 
"snippet" : "Step 1: Install Unravel Server on MapR Step 2: Enable Additional Data Collection \/ Instrumentation for MapR...", 
"body" : " \n Step 1: Install Unravel Server on MapR \n Step 2: Enable Additional Data Collection \/ Instrumentation\nfor MapR " }, 
{ "title" : "Step 1: Install Unravel Server on MapR", 
"url" : "unravel-4-3/installation-guides/mapr.html#UUID-cc7f92d7-d566-f912-54a8-dc70fbe6b4fa", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ MapR \/ Step 1: Install Unravel Server on MapR", 
"snippet" : "Table of Contents Introduction Pre-Installation Check Platform Compatibility Hardware Software Access Permissions Network 1. Configure the Host Machine Allocate a Cluster Gateway\/Edge\/Client Host with HDFS Access Configure the Host Before installing the RPM 2. Install the Unravel Server RPM on the H...", 
"body" : "\n Table of Contents \n Introduction \n Pre-Installation\nCheck \n Platform\nCompatibility \n Hardware \n Software \n Access\nPermissions \n Network \n 1.\nConfigure the Host Machine \n \nAllocate a Cluster Gateway\/Edge\/Client Host with HDFS\nAccess \n \nConfigure the Host Before installing the RPM \n \n2. Install the Unravel Server RPM on the Host Machine \n Get the\nUnravel Server RPM \n Make\nsymlinks if required \n Install\nthe Unravel Server RPM \n \nDo Host-Specific Post-Installation Actions \n \n3. Configure Unravel Server (Basic\/Core Options) \n Enable\nOptional Daemons \n Modify\nunravel.properties \n If\nKerberos is Enabled: \n If Sentry is\nEnabled: \n Switch\nUser \n \nDo Host-Specific Configuration Steps \n Restart\nUnravel Server \n 4. Log\ninto Unravel Web UI \n Congratulations! \n \n5. (Optional) Configure Unravel Server (Advanced Options) \n \nEnable Additional Data Collection\/Instrumentation \n \nRun the Unravel Web UI Configuration Wizard Introduction This topic explains how to deploy Unravel Server 4.2 on\nthe MapR converged data platform. These instructions apply\nto Unravel Server 4.2. \n Workflow Summary Pre-installation check Configure the host machine. Install the Unravel Server RPM on the host machine. Configure Unravel Server (basic\/core options). Log into Unravel Web UI. (Optional) Configure Unravel Server (advanced options). Pre-Installation Check The following installation requirements must be met for\nsuccessful installation of Unravel. Platform Compatibility MapR 5.1-6.0.1 Hadoop 1.x - 2.x Kafka 0.9, 0.10, 0.11, and 1.0 (Apache ver. equiv.) Kerberos\/MapR Tickets Hive 0.9.x - 1.2.x Spark 1.3.x - 2.0.x Hardware Architecture: x86_64 Cores: 8 RAM: 64GB minimum, 128GB for medium volume (>25,000 jobs per\nday), 256GB for high volume (>50,000 jobs per day) Disk: \/usr\/local\/unravel Disk: \/srv\/unravel For 60,000+ MR jobs per day, two or more gateway\/edge nodes are\nrecommended (\"multi-host Unravel\") Software Operating System: RedHat\/Centos 6.4 - 7.4 installed libaio.x86_64 (or disabled) should be set in\n SELINUX=permissive \/etc\/selinux\/config See Elasticsearch needs number of File Descriptors to be at\nleast 65,536. https:\/\/www.elastic.co\/guide\/en\/elasticsearch\/reference\/current\/file-descriptors.html HDFS+Hive+YARN+Spark client\/gateway, Hadoop and Hive commands\nin PATH LDAP (AD or Open LDAP) compatible for Unravel Web UI user\nauthentication (Open signup by default) On Unravel Edge-node server, please do\nnot Access Permissions If Kerberos is in use, a keytab for principal is required for\naccess to:\n Access to YARN’s “done dir” in HDFS Access to YARN’s log aggregation directory in HDFS Access to Spark event log directory in HDFS Access to file sizes under HIve warehouse directory Access to YARN Resource Manager REST API principal needs right to find out which RM is active JDBC access to the Hive Metastore (read-only user is\nsufficient) Network Port 3000 (or 4020) from users and entire cluster to Unravel\nWeb UI HDFS ports open from Hadoop cluster to Unravel Server(s) For YARN, Hive Metadata DB port open to Unravel Server(s) for\npartition reporting UDP and TCP port 4043 open from entire cluster to Unravel\nServer(s) For Oozie, port 11000 open from Unravel Server(s) to the Oozie\nserver Resource Manager (RM) port 8032 from Unravel Server(s) to the\nRM server(s) Port 4176, 4181 through 4189, 3316, 4091 must be\navailable for localhost communication between Unravel daemons or\nservices text and text with brackets ( {\n} ), except where otherwise noted, indicate where you must\nsubstitute your particular values for the text. HIGHLIGHTED must be a\nfully qualified DNS or IP address UNRAVEL_HOST_IP 1. Configure the Host Machine Allocate a Cluster Gateway\/Edge\/Client Host with HDFS Access If you do not already have a gateway\/edge\/client host\nprovisioned for Unravel server, follow these steps which are needed\nto enable the hadoop\nfs For more information about the MapR client configuration,\nsee https:\/\/maprdocs.mapr.com\/52\/ReferenceGuide\/configure.sh.html Run the following commands on Unravel Server as\n root NAME, CLDB_LIST,HISTORY_SERVER. # sudo yum install mapr-client.x86_64\n# sudo \/opt\/mapr\/server\/configure.sh -N {NAME} -c -C {CLDB_LIST} -HS {HISTORY_SERVER}\n# sudo yum install mapr-hive.noarch\n# sudo yum install mapr-spark.noarch Configure the Host Before installing the RPM Run the following commands on Unravel Server as\n root # sudo useradd -g mapr unravel\n# hadoop fs -mkdir \/user\/unravel\n# hadoop fs -chown unravel:mapr \/user\/unravel If MapR tickets are enabled, check mapr ticket for users\n unravel mapr \/etc\/unravel_ctl Check available RAM to ensure availability: # free -g For instructions on adjusting RAM allocated to MapR-FS (mfs),\nsee https:\/\/community.mapr.com\/docs\/DOC-1209 \/opt\/mapr\/conf\/warden.conf service.command.mfs.heapsize.maxpercent=10 (only change this setting on the Unravel gateway\/client\nmachine). And the restart mfs. 2. Install the Unravel Server RPM on the Host Machine Get the Unravel Server RPM See Download Unravel\nSoftware Make symlinks if required If you want the two disk areas used by Unravel to be on\ndifferent volumes, you can make symlinks to specific areas before\ninstalling (or do a mv and symlink after installing). Do it before\nthe first install if there is insufficient space on the target\npaths \/usr\/local\/unravel \/srv\/unravel Install the Unravel Server RPM # sudo rpm -U unravel-4.*.x86_64.rpm*\n# \/usr\/local\/unravel\/install_bin\/await_fixups.sh The precise filename can vary,\ndepending on how it was fetched or copied.\nThe rpm rpm -U Run the\nspecified await_fizup.sh await_fizup.sh DONE The installation creates \/usr\/local\/unravel\/ unravel \/srv\/unravel\/ \nThe master configuration file is\nin \/usr\/local\/unravel\/etc\/unravel.properties \/usr\/local\/unravel\/logs\/ unravel \/etc\/init.d\/unravel_* \/etc\/init.d\/unravel_all.sh \nDuring initial install, a bundled database is used. This can be\nswitched to use an externally managed MySQL Do Host-Specific Post-Installation Actions Run the following commands on Unravel Server: # sudo \/etc\/init.d\/unravel_all.sh stop\n# sudo \/usr\/local\/unravel\/install_bin\/switch_to_mapr.sh 3. Configure Unravel Server (Basic\/Core Options) Enable Optional Daemons Depending on your workload volume or kind of activity, you can\nenable additional daemons at this point, see Creating Multiple Workers for\nHigh Volume Data Modify unravel.properties Open \/usr\/local\/unravel\/etc\/unravel.properties vi \n# sudo vi \/usr\/local\/unravel\/etc\/unravel.properties Edit the values in unravel.properties \n \n \n Property \n Description \n Example Values \n \n \n com.unraveldata.advertised.url \n Defines the Unravel Server URL\nfor HTTP traffic. \n http:\/\/LAN_DNS:3000 \n \n \n com.unraveldata.customer.organization \n Identifies your installation\nfor reporting purposes. \n Company_and_org \n \n com.unraveldata.tmpdir \n .\nLocation where Unravel's temp file will reside Optional \n \/srv\/unravel\/tmp \n \n \n com.unraveldata.history.maxSize.weeks \n Sets retention for search\ndata. \n 26 \n \n \n com.unraveldata.hive.hook.topic.num.threads \n .\nDefines the number of threads. Default is 1. Depending on job\nvolume, increase this property to Optional N N ThousandJobsPerDay \n 1 \n \n \n com.unraveldata.job.collector.done.log.base \n HDFS path to \"done\" directory\nof MR logs \n \/var\/mapr\/cluster\/yarn\/rm\/staging\/history\/done \n \n \n com.unraveldata.job.collector.log.aggregation.base \n An HDFS path that helps locate\nMR job logs to process \n \/tmp\/logs\/*\/logs\/ \n \n \n com.unraveldata.login.admins \n Defines the usernames that can\naccess Unravel Web UI's admin pages. Default is\n admin \n admin \n \n \n com.unraveldata.spark.eventlog.location \n Where to find Spark event\nlogs \n maprfs:\/\/\/apps\/spark \n \n \n yarn.resourcemanager.webapp.address \n Resource Manager web app\naddress \n http:\/\/example.localdomain:8088 \n \n \n yarn.resourcemanager.webapp.username \n Resource Manager username to\nlogin \n \n \n yarn.resourcemanager.webapp.password \n Resource Manager password to\nlogin \n \n \n https.protocols \n Enable https access to\nResource Manager \n TLSv1.2 \n \n \n javax.jdo.option.ConnectionURL \n A JDBC connection URL \n jdbc:mysql:\/\/example.localdomain:3306\/hive OR \n \n \n javax.jdo.option.ConnectionDriverName \n JDBC driver \n com.mysql.jdbc.Driver\n OR \n \n \n javax.jdo.option.ConnectionUserName \n Hive metastore user name \n hiveuser \n \n \n javax.jdo.option.ConnectionPassword \n Hive metastore password \n \n \n com.unraveldata.metastore.databasePattern \n . Be\nselective for databases to analyze in metastore Optional \n s*|t*|d* \n \n \n oozie.server.url \n Oozie URL \n http:\/\/example.localdomain:11000\/oozie If Kerberos is Enabled: Add authentication for HDFS... Create or identify a principal and keytab for Unravel daemons to\naccess HDFS and REST when Kerberos is enabled. Add properties for Kerberos\nin \/usr\/local\/unravel\/etc\/unravel.properties \ncom.unraveldata.kerberos.principal=unravel\/myhost.mydomain@MYREALM\ncom.unraveldata.kerberos.keytab.path=\/usr\/local\/unravel\/etc\/unravel.keytab You can find and verify the principal\nthe keytab by # klist -kt KEYTAB_FILE\n The keytab file should have chmod bits 500 and be owned by\n unravel Run Unravel Daemons with\nCustom User If Sentry is Enabled: Add these permissions... Define your own alt principal with\nnarrow privileges. The alt principal can\nbe admin unravel rpm X \n \n \n Resource \n Principal \n Access \n Purpose \n \n \n hdfs:\/\/user\/spark\/applicationHistory \n Your alt principal \n read \n Spark event log \n \n \n hdfs:\/\/usr\/history\/done \n Your alt principal \n read \n MapReduce logs \n \n \n hdfs:\/\/tmp\/logs \n Your alt principal \n read \n YARN aggregation folder \n \n \n hdfs:\/\/user\/hive\/warehouse \n Your alt principal \n read \n Obtain table partition\nsizes \n \n \n Hive Metastore access \n hive \n read \n Hive table information Switch User Depending on your cluster security configuration, you will need\nto run the switch_to_user \n# sudo \/usr\/local\/unravel\/install_bin\/switch_to_user.sh x y where X Y switch_to_user Do Host-Specific Configuration Steps For MapR, there are no\nhost-specific configuration steps. Restart Unravel Server After edits to com.unraveldata.login.admins \/usr\/local\/unravel\/etc\/unravel.properties echo # sudo \/etc\/init.d\/unravel_all.sh start\n# sleep 60\n# echo \"http:\/\/({UNRAVEL_HOST_IP} -f):3000\/\" This completes the basic\/core configuration. 4. Log into Unravel Web UI Using a web browser, navigate to http:\/\/({UNRAVEL_HOST_IP} admin unraveldata For the free trial version, use the Chrome web browser. Congratulations! Unravel Server is up and running. Unravel Web UI displays\ncollected data. Check Unravel Web UI for MR jobs loading: on the\n Applications Map\nReduce For instructions on using Unravel Web UI, see the User Guide 5. (Optional) Configure Unravel Server (Advanced Options) Enable Additional Data Collection\/Instrumentation Install the Unravel Sensor Parcel on gateway\/edge\/client Step 2: Enable Additional\nData Collection \/ Instrumentation for MapR Run the Unravel Web UI Configuration Wizard Run the Unravel Web UI configuration wizard to choose additional\nconfiguration options. For instructions on configuring advanced\noptions, see the Advanced Topics " }, 
{ "title" : "Step 2: Enable Additional Data Collection \/ Instrumentation for MapR", 
"url" : "unravel-4-3/installation-guides/mapr.html#UUID-6462597c-ddfa-53a1-fc4c-bab4e04c980f", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Installation Guides \/ MapR \/ Step 2: Enable Additional Data Collection \/ Instrumentation for MapR", 
"snippet" : "Table of Contents Introduction 1. Enable Additional Instrumentation on Unravel Server's Host 2. Confirm that Unravel Web UI Shows Additional Data 3. Confirm and Adjust the Settings in yarn-site.xml 5. Enable Instrumentation manually by updating the following files: Update hive-site.xml Update hive-e...", 
"body" : "\n Table of Contents \n \nIntroduction \n \n1. Enable Additional Instrumentation on Unravel Server's\nHost \n \n2. Confirm that Unravel Web UI Shows Additional Data \n \n3. Confirm and Adjust the Settings in yarn-site.xml \n \n5. Enable Instrumentation manually by updating the following\nfiles: \n \nUpdate hive-site.xml \n \nUpdate hive-env.sh \n \nUpdate hadoop-env.sh \n \nUpdate mapred-site.xml Introduction This topic explains how to enable additional data\ncollection or instrumentation on the MapR converged data\nplatform. These instructions apply to Unravel Server v4.0.\nFor older versions of Unravel Server, contact Unravel Support. \n Workflow Summary Enable additional instrumentation on Unravel Server's\nhost. Enter correct value for Hive Metastore, Resource Manager and\nOozie properties. Confirm that Unravel Web UI shows additional data. Confirm and adjust the settings in\n yarn-site.xml Enable additional instrumentation on other hosts in the\ncluster. 1. Enable Additional Instrumentation on Unravel Server's Host Substitute valid values for: -\nfully qualified domain name or IP address UNRAVEL_HOST_IP - target Spark version,\ne.g., 1.3.0, 1.6.0,\n2.0.1. SPARK_VERSION_X.Y.Z \n- target Hive version, e.g., 1.2.0. HIVE_VERSION _X.Y.Z Best practice is to enable instrumentation on Unravel Server\nitself for testing, practice, and demonstration purposes, before\nenabling instrumentation on other gateway\/edge\/client nodes that do\nreal client work (Hive queries, Map-Reduce jobs, Spark, and so\non). running Before unravel_mapr_setup.sh \n wget \n unzip \n hive \n spark-shell Run the shell script unravel_mapr_setup.sh host1 \n# sudo \/usr\/local\/unravel\/install_bin\/unraveldata-clients\/unravel_mapr_setup.sh install -y --unravel-server {UNRAVEL_HOST_IP}:3000 --spark-version {SPARK_VERSION_X.Y.Z} --hive-version {HIVE_VERSION_X.Y.Z} Hive hook jar is installed under: \n \/usr\/local\/unravel_client\/ Resource metrics sensor jars are installed under: \n \/usr\/local\/unravel-agent\/ Configuration changes (for MapR 5.2) are made to: \n \/opt\/mapr\/spark\/spark-2.0.1\/conf\/spark-defaults.conf \n \/opt\/mapr\/hive\/hive-1.2\/conf\/hive-site.xml \n \/opt\/mapr\/hive\/hive-1.2\/conf\/hive-env.sh Once the files are present on edge host where Unravel rpm is\ninstalled, you can tar these changes\/additions up and put on other\nhosts, if that is more convenient than running the script. In all\ncases, instrumented nodes must be able to open port 4043 of Unravel\nServer (host2 if multi-host Unravel install). 2. Confirm that Unravel Web UI Shows Additional Data Run a Hive job using a test script provided by Unravel\nServer: This is where you can see the\neffects of the instrumentation setup. Best practice is to run this\ntest script on Unravel Server rather than on a gateway\/edge\/client\nnode. That way you can verify that instrumentation is working\nfirst, and then enable instrumentation on other gateway\/edge\/client\nnodes. be user that can create tables in the default\ndatabase. If you need to use a different database, copy the script\nand edit it to change the target database. someUser must This script creates a uniquely named table in the default\ndatabase, adds some data, runs a Hive query on it, and then deletes\nthe table. It runs the query twice using different workflow tags so you can\nclearly see the two different runs of the same workflow in Unravel\nWeb UI. \n# sudo -u {someUser} \/usr\/local\/unravel\/install_bin\/hive_test_simple.sh 3. Confirm and Adjust the Settings in yarn-site.xml Check specific properties in\n \/opt\/mapr\/hadoop\/hadoop-2.7.0\/etc\/hadoop\/yarn-site.xml : yarn.resourcemanager.webapp.address <property>\n<name>yarn.resourcemanager.webapp.address<\/name>\n<value>10.0.0.110:8088<\/value>\n<source>yarn-site.xml<\/source>\n<\/property> : yarn.log-aggregation-enable <property>\n<name>yarn.log-aggregation-enable<\/name>\n<value>true<\/value>\n<description>For log aggregations<\/description>\n<\/property> 4.\nEnable Additional Instrumentation on Other Hosts in the\nCluster To instrument more servers, you can use the setup script\nwe provide or see the effect it has and replicate it using your own\nprovisioning automation system. If you already have a way to\ncustomize and deploy\n hive-site.xml yarn-site.xml Run the shell script unravel_mapr_setup.sh Copy the newly edited yarn-site.xml Do a rolling-restart of HiveServer2. 5. Enable Instrumentation manually by updating the following files: \n hive-site.xml \n hive-env.sh \n spark-defaults.conf \n hadoop-env.sh \n mapred-site.xml Once the files are updated on edge host where Unravel rpm is\ninstalled, you can scp Be sure to substitute valid values for: -\nfully qualified domain name or IP address UNRAVEL_HOST_IP - target Spark version,\ne.g., 1.3.0, 1.6.0,\n2.0.1. SPARK_VERSION_X.Y.Z \n- target Hive version, e.g., 1.2.0. HIVE_VERSION _X.Y.Z Update hive-site.xml Copy the content\nin \/usr\/local\/unravel\/hive-hook\/hive-site.xml.snip \/opt\/mapr\/hive\/hive-HIVE_VERSION_X.Y.Z\/conf\/hive-site.xml {UNRAVEL_HOST_IP}) <property>\n <name>com.unraveldata.host<\/name>\n <value>{UNRAVEL_HOST_IP}<\/value>\n <description>Unravel hive-hook processing host<\/description>\n<\/property>\n\n<property>\n <name>com.unraveldata.hive.hook.tcp<\/name>\n <value>true<\/value>\n<\/property>\n\n<property>\n <name>com.unraveldata.hive.hdfs.dir<\/name>\n <value>\/user\/unravel\/HOOK_RESULT_DIR<\/value>\n <description>destination for hive-hook, Unravel log processing<\/description>\n<\/property>\n\n<property>\n <name>hive.exec.driver.run.hooks<\/name>\n <value>com.unraveldata.dataflow.hive.hook.HiveDriverHook<\/value>\n <description>for Unravel, from unraveldata.com<\/description>\n<\/property>\n\n<property>\n <name>hive.exec.pre.hooks<\/name>\n <value>com.unraveldata.dataflow.hive.hook.HivePreHook<\/value>\n <description>for Unravel, from unraveldata.com<\/description>\n<\/property>\n\n<property>\n <name>hive.exec.post.hooks<\/name>\n <value>com.unraveldata.dataflow.hive.hook.HivePostHook<\/value>\n <description>for Unravel, from unraveldata.com<\/description>\n<\/property>\n\n<property>\n <name>hive.exec.failure.hooks<\/name>\n <value>com.unraveldata.dataflow.hive.hook.HiveFailHook<\/value>\n <description>for Unravel, from unraveldata.com<\/description>\n<\/property>\n\n<\/configuration> Update hive-env.sh In \/opt\/mapr\/hive\/hive-HIVE_VERSION_X.Y.Z\/conf\/hive-env.sh ({HIVE_VERSION_X.Y.Z}). \nexport AUX_CLASSPATH=${AUX_CLASSPATH}:\/usr\/local\/unravel_client\/unravel-hive-{HIVE_VERSION X.Y.Z}-hook.jar\nexport HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}:\/usr\/local\/unravel_client Update spark-defaults.conf In \/opt\/mapr\/spark\/spark-SPARK_VERSION_X.Y.Z\/conf\/ spark-defaults.conf {UNRAVEL_HOST_IP} {SPARK_VERSION_X.Y.Z} spark.unravel.server.hostport {UNRAVEL_HOST_IP}:4043\nspark.eventLog.dir maprfs:\/\/\/apps\/spark\nspark.history.fs.logDirectory maprfs:\/\/\/apps\/spark\nspark.driver.extraJavaOptions -javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=spark-{SPARK_VERSION_X.Y.Z},config=driver\nspark.executor.extraJavaOptions -javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=spark-{SPARK_VERSION_X.Y.Z},config=executor Update hadoop-env.sh In \/opt\/mapr\/hadoop\/hadoop-HADOOP_VERSION_X.Y.Z\/etc\/hadoop\/hadoop-env.sh ({HIVE_VERSION_X.Y.Z}). \nexport HADOOP_CLASSPATH=${HADOOP_CLASSPATH}:\/usr\/local\/unravel_client\/unravel-hive-{HIVE_VERSION_X.Y.Z}.0-hook.jar Update mapred-site.xml In \/opt\/mapr\/hadoop\/hadoop-HADOOP_VERSION_X.Y.Z\/etc\/hadoop\/mapred-site.xml {UNRAVEL_HOST_IP} <property>\n <name>mapreduce.task.profile<\/name>\n <value>true<\/value>\n<\/property>\n\n<property>\n <name>mapreduce.task.profile.maps<\/name>\n <value>0-5<\/value>\n<\/property>\n\n<property>\n <name>mapreduce.task.profile.reduces<\/name>\n <value>0-5<\/value>\n<\/property>\n\n<property>\n <name>mapreduce.task.profile.params<\/name>\n <value>-javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=mr -Dunravel.server.hostport={UNRAVEL_HOST_IP}:4043<\/value>\n<\/property>\n\n<property>\n <name>yarn.app.mapreduce.am.command-opts<\/name>\n <value>-javaagent:\/usr\/local\/unravel-agent\/jars\/btrace-agent.jar=libs=mr -Dunravel.server.hostport=172.36.1.126:4043<\/value>\n<\/property>\n\n Make sure the original value of yarn.app.mapreduce.am.command-opts " }, 
{ "title" : "User Guide", 
"url" : "unravel-4-3/user-guide.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide", 
"snippet" : "Unravel Web UI helps you to analyze, optimize, and troubleshoot big data applications and operations. Getting Started Common UI Features The Operations Page The Applications Page The Reports Page Auto Actions Use Cases Detecting Resource Contention in the Cluster Identifying Rogue Applications Optim...", 
"body" : "Unravel Web UI helps you to analyze,\noptimize, and troubleshoot big data applications and\noperations. \n Getting Started \n Common UI Features \n The Operations Page \n The Applications Page \n The Reports Page \n Auto Actions \n Use Cases \n Detecting Resource Contention\nin the Cluster \n Identifying Rogue\nApplications \n Optimizing the Performance of\nSpark Applications \n Kafka Insights " }, 
{ "title" : "Getting Started", 
"url" : "unravel-4-3/user-guide/getting-started.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide \/ Getting Started", 
"snippet" : "Use Case Videos Case #1: How to Search for Applications and Optimize\/Tune a Hive Application Case #2: How to \"Root Cause\" Issues with a Workflow that Missed Its SLA Case #3: How to Debug Failed Applications Case #4: How to Review Spark Applications and Identify Areas for Performance Improvements Run...", 
"body" : " \n Use Case Videos \n \nCase #1: How to Search for Applications and Optimize\/Tune a Hive\nApplication \n \nCase #2: How to \"Root Cause\" Issues with a Workflow that Missed Its\nSLA \n Case #3: How\nto Debug Failed Applications \n \nCase #4: How to Review Spark Applications and Identify Areas for\nPerformance Improvements \n Running\nthe Configuration Wizard \n Setting Up\nAccess to Big Data Components \n \nCreating Users and Setting Up Email\/SMTP, LDAP, Kerberos " }, 
{ "title" : "Use Case Videos", 
"url" : "unravel-4-3/user-guide/getting-started.html#UUID-ebf72ccc-4661-7a3e-cdb9-41a04a64c01f_id_GettingStarted-UseCaseVideos", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide \/ Getting Started \/ Use Case Videos", 
"snippet" : "Under Construction Please see Version 4.2 Getting Started Case #1: How to Search for Applications and Optimize\/Tune a Hive Application Case #2: How to \"Root Cause\" Issues with a Workflow that Missed Its SLA Case #3: How to Debug Failed Applications Case #4: How to Review Spark Applications and Ident...", 
"body" : " Under Construction Please see Version 4.2 Getting\nStarted Case #1: How to Search for Applications and Optimize\/Tune a Hive Application Case #2: How to \"Root Cause\" Issues with a Workflow that Missed Its SLA Case #3: How to Debug Failed Applications Case #4: How to Review Spark Applications and Identify Areas for Performance Improvements " }, 
{ "title" : "Running the Configuration Wizard", 
"url" : "unravel-4-3/user-guide/getting-started.html#UUID-ebf72ccc-4661-7a3e-cdb9-41a04a64c01f_id_GettingStarted-RunningtheConfigurationWizard", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide \/ Getting Started \/ Running the Configuration Wizard", 
"snippet" : "After you install the Unravel Server RPM, you can run Unravel Web UI's configuration wizard to: Set up access to various Big Data components (HDFS, Hive, Oozie, and so on). Create users Set up email\/SMTP, LDAP, Kerberos The configuration wizard informs you of errors and continuously checks for faile...", 
"body" : "After you install the Unravel Server RPM, you can run Unravel\nWeb UI's configuration wizard to: Set up access to various Big Data components (HDFS, Hive,\nOozie, and so on). Create users Set up email\/SMTP, LDAP, Kerberos The configuration wizard informs you of errors and continuously\nchecks for failed and incorrect settings. To start the\nconfiguration wizard, click Admin Manage Configuration The Unravel Web UI configuration wizard is available only for\nthe admin Setting Up Access to Big Data Components Creating Users and Setting Up Email\/SMTP, LDAP, Kerberos " }, 
{ "title" : "Common UI Features", 
"url" : "unravel-4-3/user-guide/common-ui-features.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide \/ Common UI Features", 
"snippet" : "Every page has the Unravel Title Bar. No matter what your permissions the pages available to you are listed on the left with the one you are viewing underlined and noted below in the black bar. To the right there is a search box, Docs Supported Roles Role Based Access Control If you are enduser rest...", 
"body" : " Every page has the Unravel Title Bar. No matter what your\npermissions the pages available to you are listed on the left with\nthe one you are viewing underlined and noted below in the black\nbar. To the right there is a search box, Docs Supported Roles Role Based Access Control If you are enduser restricted by \nRole Based Access Control Applications About Logout If you are unrestricted enduser or an admin, you have all the\npages available with possible read\/write restrictions. The\npull-down menu has Manage About Logout If your admin has disabled\n Support If you can configure the date range time period cluster(s) When there are multiple tabs, click on the tab to display its\ncontents. When detailed or further information is available open section\n( ) is in the upper right hand corner; click\non it for further information. To expand section to the width of the entire tile click on the\ndouble arrows displayed ( ); to close it click on ( ). Clicking on the application name\/id\/workflow usually bring ups\ninformation on the appplication, fragment etc, i.e., the Spark\nApplication Manager, table information, etc. Lists\/Tables Can be sorted by a column, i.e., start time, in ascending or descending order. The\nsort column highlights the arrow indicating the sort order\n( \nClicking on a column being used reverses the sort order. If you can chose which columns to display a plus ( ) is on the right end of the table header. Click on\nit to see the column headings; check\/uncheck the column heading to\nshow\/hide the column. When applicable, the application status is color coded:\n Clicking on the app name\/id\/workflow usually bring ups the\ninformation on the app, i.e., the Spark Application Manager, table\ninformation, etc. When applicable, the Notifications ) notes if Unravel has tuning suggestions\n( ), an Auto Action alert ( ) or both ( ). When relevant there is an Auto Actions\/Events column\n( ). The number of auto actions\/events (0-n)\ntriggered is noted. When an application has a parent a link to it will appear in\nthe GoTo ), its title bar or a more info\nglyph ( ). Click on it glyph display its parent APM. A block glyph ( Graphs (see Operations | Usage Details |\nInfrastructure Hovering over a line in a graph causes the information to be\ndisplayed in a text box ( ). When \" Applications running at mm\/dd\/yy\nhh:mm:ss\" Clicking Show More ( If graph can be displayed based upon Group By Tags Metric ) in the upper right hand corner. Click to print or download the information in the\ngraph in various forms, i.e., jpg, png, csv. If you can zoom in\/out of a diagram\/execution graph the\nmagnifiers ( , ) in the upper right hand corner. Click\n to return to the initial view. " }, 
{ "title" : "Auto Actions", 
"url" : "unravel-4-3/user-guide/auto-actions.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide \/ Auto Actions", 
"snippet" : "Auto Actions Overview Creating Auto Actions Expert Rule Same Logical Operator Snooze Feature Sample Auto Actions Supported cluster metrics Running Auto Action Demos...", 
"body" : " \n Auto Actions\nOverview \n Creating Auto\nActions \n Expert Rule \n Same Logical Operator \n Snooze Feature \n Sample Auto Actions \n Supported cluster\nmetrics \n Running Auto Action\nDemos " }, 
{ "title" : "Auto Actions Overview", 
"url" : "unravel-4-3/user-guide/auto-actions.html#UUID-b13b5f65-0fc9-5759-af3e-0beb2b2b2771", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ User Guide \/ Auto Actions \/ Auto Actions Overview", 
"snippet" : "Table of Contents Viewing Auto Actions 'Snoozing' Auto Actions Unravel's Auto Actions automates the monitoring of your compute cluster by allowing you to define complex actionable rules on different cluster metrics. You can use an auto action to alert you to a situation needing manual intervention, ...", 
"body" : "\n Table of Contents \n Viewing Auto\nActions \n 'Snoozing'\nAuto Actions Unravel's Auto Actions automates the monitoring of\nyour compute cluster by allowing you to define complex actionable\nrules on different cluster metrics. You can use an auto action to\nalert you to a situation needing manual intervention, e.g.,\nresource contention or stuck jobs. Additionally, it can be set to\nautomatically kill an application or move it to a different\nqueue. The Unravel Server processes auto actions by: Collecting various metrics from the\ncluster(s), Aggregating the collected metrics according to\nuser-defined rules, Detecting rule violations, and Applying defined actions for each rule\nviolation. Each rule consists of: A logical expression that is used to aggregate cluster\nmetrics and to evaluate the rule. A rule has two\nconditions: The conditions which\ncause a violation, e.g., the number of jobs running, memory\nused. Prerequisite conditions: Who\/what\/when can cause\nthe violation, e.g., user, applications Defining conditions: for Unravel Server to execute\nwhenever it detects a rule violation. Actions Viewing Auto Actions Select Manage | Auto Actions. The Auto Actions tab provides a quick way to view auto\nactions and quickly see their status, along with its defined\nactions and scope. The tab displays all defined auto actions\nseparated into an Active and Inactive list. You\nenable\/disable by clicking the check box on the left. You can edit\n( define new auto\nactions Hovering over the auto action's name gives you the\ndescription which was entered when defining the auto action.\nHovering over action or scope glyph brings up its detail. For\nexample, for the active auto action above: rule description: , email action: an email is sent to only 1 person, , and queue scope: is three queues: . The Actions Scope quicktest must Expert Rule quicktest in MR History of\nRuns By default all actions are off. Possible actions\nare: Send an Email ( ) Kill the App ( ) Move the app to another queue ( ), and Send a Http post ( ) By default the various scopes apply to all, i.e., all\napplications and constantly on. The scopes are: User ( ) Queue ( ), Cluster ( ), Application ( ), Time ( ), Sustained Violation: This is not shown in the auto actions\nlist. If you have not defined a particular action or scope, i.e., it's\nusing the default, the glyph is grey ( The history of runs\ncontains an entry for each time the auto action was triggered.\nClick on the run's Link Reports Resources The Cluster View shows a time slice, ±5 minutes from when the\nauto action was triggered and lists all the applications running\nduring that period. This application table is similar to the\napplication table shown under. This application table is similar\nto the application table shown under Applications |\nApplications Notifications 'Snoozing' Auto Actions The snooze function prevents\nautomatic actions from being repeated during a specified period of\ntime, if and only if, it is the same violation\ncontext and the action adds no further information to the\nviolation, i.e., the new violation is essentially\nnoise. See Snooze Feature \n \n \n Property \n Definition \n Possible Value \n Default \n \n \n com.unraveldata.auto.action.snooze.period.sec \n The time repeated violations are be ignored for the violator,\ni.e., app, user. If the violation is still occurring when\n awakened snoozed An auto action containing a kill move app Value is in seconds. \n 0: snooze is turned off. > 0: snooze is on, there is no no upper bound. \n 1 hour (3,600 seconds) When you change the snooze time period all applications\ncurrently snoozed are reset. Upon next violation the application is\n\"snoozed\" using new snooze value. To change the snooze time On Unravel Server, open\n \/usr\/local\/unravel\/etc\/unravel.properties vi \n# sudo vi \/usr\/local\/unravel\/etc\/unravel.properties Search for com.unraveldata.auto.action.snooze.period.sec. \ncom.unraveldata.auto.action.snooze.period.sec=7200 Restart the JCS2 daemon. # service unravel_jcs2 restart " }, 
{ "title" : "Advanced Topics", 
"url" : "unravel-4-3/advanced-topics.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Advanced Topics", 
"snippet" : "Backing-up, Disaster Recovery and Reverting to Prior Version Cluster Wide Report Configurations Custom Configurations Configure Permission for Unravel daemons on CDH Sentry Secured Cluster Configuring Multiple Hosts for Unravel Server Creating Multiple Workers for High Volume Data Defining a Custom ...", 
"body" : " \n Backing-up, Disaster Recovery\nand Reverting to Prior Version \n Cluster Wide Report \n Configurations \n Custom Configurations \n Configure Permission for\nUnravel daemons on CDH Sentry Secured Cluster \n Configuring Multiple Hosts for\nUnravel Server \n Creating Multiple Workers for\nHigh Volume Data \n Defining a Custom Web UI\nPort \n Run Unravel Daemons with\nCustom User \n Setting Retention Time in\nUnravel Server \n Setting Up Email for Auto\nActions and Collaboration \n Spark Properties for Spark\nWorker daemon @ Unravel \n Security Configurations \n Adding More Admins to Unravel\nWeb UI \n Adding SSL and TLS to Unravel\nWeb UI \n Alternate Kerberos Principal\nfor Cluster Access on CDH \n Configure HDFS permission for\nUnravel on CDH Sentry Secured Cluster \n Configure Hive Metastore\nPermissions \n Disabling Browser\nTelemetry \n Disabling Support\/Comments\nPanel \n Enabling TLS to Unravel Web\nUI Directly \n Encrypting Passwords in\nUnravel Properties and Settings \n Integrating LDAP\nAuthentication for Unravel Web UI \n Kafka Security \n Restrict direct access to Web\nUI \n Using a Private Certificate\nAuthority with Unravel \n Connecting to\/Configuration of\na Kafka Stream \n Creating Active Directory\nKerberos Principals and Keytabs for Unravel \n Creating an AWS RDS CloudWatch\nAlarm for FreeStorageSpace \n Creating Application\nTags \n EMR Support Matrix \n Hive Metastore \n Connecting to a Hive\nMetastore \n Hive Metastore\nConfiguration \n Installing MySQL or Compatible\nDatabase for Unravel \n Roles and Role Based Access\nControl \n Role Based Access Control\n(RBAC) \n Supported Roles \n Running Verification Scripts\nand Benchmarks \n Unravel APIs \n Use Case - Auto Actions and\nPagerduty \n Unravel Servers and\nSensors \n Installing Sensors \n Unravel Sensor for Individual\nApplications Submitted Through spark-submit \n Unravel Sensor for Individual\nHive Queries \n Upgrading the Unravel Server\nand Sensors \n Uninstalling Unravel\nServer \n Uploading Spark Programs to\nUnravel \n Workflows \n Tagging Workflows \n Monitoring Oozie\nWorkflows \n Monitoring Airflow\nWorkflows \n Tagging a Hive on Tez\nQuery " }, 
{ "title" : "Troubleshooting", 
"url" : "unravel-4-3/troubleshooting.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Troubleshooting", 
"snippet" : "Sending Diagnostics to Unravel Support <In progress> If you can't reach Unravel Server, (i) ping LANS_DNS, (ii) try this workaround:...", 
"body" : " Sending Diagnostics to Unravel\nSupport <In progress> If you can't reach Unravel Server, (i) ping LANS_DNS, (ii) try\nthis workaround: " }, 
{ "title" : "Appendices", 
"url" : "unravel-4-3/appendices.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Appendices", 
"snippet" : "Event List Resource Metrics Some Keywords and Error Messages Server Daemon Reference Finding Unravel properties' values in Microsoft's Azure...", 
"body" : " \n Event List \n Resource Metrics \n Some Keywords and Error\nMessages \n Server Daemon\nReference \n Finding Unravel properties'\nvalues in Microsoft's Azure " }, 
{ "title" : "Release Notes", 
"url" : "unravel-4-3/release-notes.html", 
"breadcrumbs" : "UN43 (Unravel 4.3) \/ Unravel 4.3 \/ Release Notes", 
"snippet" : "v4.3.0 v4.3.1.x v4.3.1.0 v4.3.1.1 v4.3.1.2 v4.3.1.3 v4.3.1.4 v4.3.1.5 v4.3.1.6 v4.3.1.7 v4.3.1.8 - not available v4.3.1.9 v4.3.1.10...", 
"body" : " \n v4.3.0 \n v4.3.1.x \n v4.3.1.0 \n v4.3.1.1 \n v4.3.1.2 \n v4.3.1.3 \n v4.3.1.4 \n v4.3.1.5 \n v4.3.1.6 \n v4.3.1.7 \n v4.3.1.8 - not\navailable \n v4.3.1.9 \n v4.3.1.10 " }
]
$(document).trigger('search.ready');
});